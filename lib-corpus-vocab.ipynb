{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52dfd6b-aee7-4e79-b8c0-278b05639821",
   "metadata": {},
   "source": [
    "# Creating LIB, CORPUS, and VOCAB tables\n",
    "\n",
    "Charlie Perez (cwp5xyj)\n",
    "\n",
    "A note that the process of clipping the text files and creating the LIB table will be largely done by hand - I really want to preserve things like the Table of Contents for later work (given Martin's writing style, the exact POV of the chapter is important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49dcf16-b934-4cc6-b4c9-7cb5b61b5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px\n",
    "import configparser\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8945aa6-53d2-4885-9ab4-3b9e75f274b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96a213fa-e3c9-4da1-8377-f4ab5d24b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think I will have to remove Fire and Blood - it wouldn't match well anyways, and would be much more of a novelty\n",
    "\n",
    "metadata = [\n",
    "    {\n",
    "        'ID': 1,\n",
    "        'file': 'agot.txt',\n",
    "        'title': 'A Game of Thrones',\n",
    "        'clip_range': (212, 14145),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (20, 165)\n",
    "    },\n",
    "    {\n",
    "        'ID': 2,\n",
    "        'file': 'acok.txt',\n",
    "        'title': 'A Clash of Kings',\n",
    "        'clip_range': (382, 16150),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (55, 334)\n",
    "    },\n",
    "    {\n",
    "        'ID': 3,\n",
    "        'file': 'asos.txt',\n",
    "        'title': 'A Storm of Swords',\n",
    "        'clip_range': (451, 20253),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (59, 386)\n",
    "    },\n",
    "    {\n",
    "        'ID': 4,\n",
    "        'file': 'affc.txt',\n",
    "        'title': 'A Feast for Crows',\n",
    "        'clip_range': (343, 13963),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (87, 271)\n",
    "    },\n",
    "    {\n",
    "        'ID': 5,\n",
    "        'file': 'adwd.txt',\n",
    "        'title': 'A Dance with Dragons',\n",
    "        'clip_range': (344, 18874),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (104, 250)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349dc8a-982a-42a6-94c1-332fe3d4a561",
   "metadata": {},
   "source": [
    "#### Create LIB table\n",
    "\n",
    "With formatted table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454f7139-480a-4d3e-b072-5d106089cfa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'{os.getcwd()}/data'\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d007f0c4-96b2-4e4e-ae66-a5cb6407c298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>clip_range</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>TOC_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "      <td>(212, 14145)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(20, 165)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Clash of Kings</td>\n",
       "      <td>(382, 16150)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(55, 334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Storm of Swords</td>\n",
       "      <td>(451, 20253)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(59, 386)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Feast for Crows</td>\n",
       "      <td>(343, 13963)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(87, 271)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "      <td>(344, 18874)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(104, 250)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file                 title  \\\n",
       "ID                                                                            \n",
       "1   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Game of Thrones   \n",
       "2   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...      A Clash of Kings   \n",
       "3   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Storm of Swords   \n",
       "4   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Feast for Crows   \n",
       "5   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...  A Dance with Dragons   \n",
       "\n",
       "      clip_range chap_regex   TOC_range  \n",
       "ID                                       \n",
       "1   (212, 14145)  ^[A-Z ]+$   (20, 165)  \n",
       "2   (382, 16150)  ^[A-Z ]+$   (55, 334)  \n",
       "3   (451, 20253)  ^[A-Z ]+$   (59, 386)  \n",
       "4   (343, 13963)  ^[A-Z ]+$   (87, 271)  \n",
       "5   (344, 18874)  ^[A-Z ]+$  (104, 250)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB = pd.DataFrame(metadata)\n",
    "LIB.file = data_dir + '/' + LIB.file\n",
    "LIB.set_index('ID', inplace=True)\n",
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a853a75-16c1-4f68-8730-27ab0e6d9b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/agot.txt (212, 14145) ^[A-Z ]+$ (20, 165)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/acok.txt (382, 16150) ^[A-Z ]+$ (55, 334)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/asos.txt (451, 20253) ^[A-Z ]+$ (59, 386)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/affc.txt (343, 13963) ^[A-Z ]+$ (87, 271)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/adwd.txt (344, 18874) ^[A-Z ]+$ (104, 250)\n"
     ]
    }
   ],
   "source": [
    "for idx, row in LIB.iterrows():\n",
    "    src, clip_range, chap_ragex, TOC_range = row.file, row.clip_range, row.chap_regex, row.TOC_range\n",
    "    print(src, clip_range, chap_ragex, TOC_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5eeb19b-ac32-4c1a-8011-1ee572da37a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_lines(src):\n",
    "    text_lines = open(src,'r', encoding= 'utf-8').readlines()\n",
    "    LINES = pd.DataFrame({'line_str':text_lines})\n",
    "    LINES.index.name = 'line_id'\n",
    "    return LINES\n",
    "\n",
    "def extract_TOC(LINES, TOC_range):\n",
    "    TOC_lines = LINES.loc[TOC_range[0]:TOC_range[1]].copy()\n",
    "    contents = []\n",
    "    chapter_counts = defaultdict(int)\n",
    "    for i in TOC_lines.line_str.str.strip('\\n'):\n",
    "        if i != '':\n",
    "            if i != 'Prologue' and i != 'Epilogue':\n",
    "                chapter_counts[i] += 1\n",
    "                contents.append(f'{i} {chapter_counts[i]}')\n",
    "            else:\n",
    "                contents.append(i)\n",
    "    return contents\n",
    "\n",
    "def parse_tokens(LINES, clip_range, chap_regex, book_id):\n",
    "    LINES = LINES.loc[clip_range[0]:clip_range[1]].copy()\n",
    "    OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "    \n",
    "    LINES.line_str = LINES.line_str.str.replace(r'\\n+', ' ', regex=True).str.strip()\n",
    "    chap_lines = LINES.line_str.str.match(chap_regex, case=False)\n",
    "\n",
    "    LINES.loc[chap_lines, 'chap_num'] = [i+1 for i in range(LINES.loc[chap_lines].shape[0])]\n",
    "    LINES.chap_num = LINES.chap_num.ffill()\n",
    "\n",
    "    LINES = LINES.dropna(subset=['chap_num'])\n",
    "    LINES = LINES.loc[~chap_lines]\n",
    "    LINES.chap_num = LINES.chap_num.astype('int')\n",
    "\n",
    "    CHAPS = LINES.groupby(OHCO[:1])\\\n",
    "        .line_str.apply(lambda x: '\\n'.join(x))\\\n",
    "        .to_frame('chap_str')\n",
    "\n",
    "    CHAPS['chap_str'] = CHAPS.chap_str.str.strip()\n",
    "\n",
    "    para_pat = r'\\n\\n+'\n",
    "\n",
    "    PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "        .to_frame('para_str').sort_index()\n",
    "    PARAS.index.names = OHCO[:2]\n",
    "\n",
    "    PARAS['para_str'] = PARAS['para_str'].str.replace(r'\\n', ' ', regex=True)\n",
    "    PARAS['para_str'] = PARAS['para_str'].str.strip()\n",
    "    PARAS = PARAS[~PARAS['para_str'].str.match(r'^\\s*$')]\n",
    "\n",
    "    SENTS = PARAS.para_str\\\n",
    "                    .apply(lambda x: pd.Series(nltk.sent_tokenize(x), dtype='string'))\\\n",
    "                    .stack()\\\n",
    "                    .to_frame('sent_str')\n",
    "\n",
    "    SENTS.index.names = OHCO[:3]\n",
    "\n",
    "    TOKENS = SENTS.sent_str\\\n",
    "                    .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\n",
    "    TOKENS = TOKENS.stack().to_frame('pos_tuple')\n",
    "    TOKENS['pos'] = TOKENS.pos_tuple.apply(lambda x: x[1])\n",
    "    TOKENS['token_str'] = TOKENS.pos_tuple.apply(lambda x: x[0])\n",
    "    TOKENS['term_str'] = TOKENS.token_str.str.lower()\n",
    "\n",
    "    TOKENS.index.names = OHCO[:4]\n",
    "    \n",
    "    TOKENS.reset_index(inplace=True)\n",
    "    TOKENS['book_id'] = book_id\n",
    "    OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "    TOKENS.set_index(OHCO, inplace=True)\n",
    "    \n",
    "    punc_pos = ['$', \"''\", '(', ')', ',', '--', '.', ':', '``']\n",
    "    TOKENS['term_str'] = TOKENS[~TOKENS.pos.isin(punc_pos)].token_str\\\n",
    "                        .str.replace(r'[\\W_]+', '', regex=True).str.lower()  \n",
    "    return TOKENS\n",
    "    \n",
    "    \n",
    "def parse_corpus(LIB):\n",
    "    contents = []\n",
    "    TOKENS = pd.DataFrame()\n",
    "    for idx, row in LIB.iterrows():\n",
    "        book_id, src, clip_range, chap_regex, TOC_range = idx, row.file, row.clip_range, row.chap_regex, row.TOC_range\n",
    "        LINES = read_lines(src)\n",
    "        ind_contents = extract_TOC(LINES, TOC_range)\n",
    "        ind_TOKENS = parse_tokens(LINES, clip_range, chap_regex, book_id)\n",
    "        \n",
    "        contents.append(ind_contents)\n",
    "        TOKENS = pd.concat([TOKENS, ind_TOKENS])\n",
    "    \n",
    "    return contents, TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1feff6b-d2ba-4c3c-a40e-c331442d68a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04221694-2d76-45e9-958b-9ecd3deba6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 649 ms, total: 1min 44s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "contents, TOKENS = parse_corpus(LIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "787ba574-3ebb-4ec5-87f6-ec04163946b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(“, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>“</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(We, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>We</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(should, MD)</td>\n",
       "      <td>MD</td>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(start, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(back, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                \n",
       "1       1        0        0        0               (“, IN)   IN         “   \n",
       "                                   1             (We, PRP)  PRP        We   \n",
       "                                   2          (should, MD)   MD    should   \n",
       "                                   3           (start, VB)   VB     start   \n",
       "                                   4            (back, RB)   RB      back   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "1       1        0        0        0                   \n",
       "                                   1               we  \n",
       "                                   2           should  \n",
       "                                   3            start  \n",
       "                                   4             back  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4528de05-bdbd-48a6-8dcd-774e53d68cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">70</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">140</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>3</th>\n",
       "      <td>(hands, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>hands</td>\n",
       "      <td>hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(,, ,)</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(daggers, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>daggers</td>\n",
       "      <td>daggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(., .)</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                  \n",
       "5       70       140      0        3            (hands, NNS)  NNS     hands   \n",
       "                                   4                  (,, ,)    ,         ,   \n",
       "                                   5               (the, DT)   DT       the   \n",
       "                                   6          (daggers, NNS)  NNS   daggers   \n",
       "                                   7                  (., .)    .         .   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "5       70       140      0        3            hands  \n",
       "                                   4              NaN  \n",
       "                                   5              the  \n",
       "                                   6          daggers  \n",
       "                                   7              NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe20d78e-1fca-4653-b0d3-da7fdb6044d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcontents\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'contents' is not defined"
     ]
    }
   ],
   "source": [
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31085e7-4baa-47bc-98cd-16c24e328f88",
   "metadata": {},
   "source": [
    "Need to manually mess with the AFFC and ADWD chapters - gonna be a bit of a pain\n",
    "\n",
    "#### Create Vocabulary from TOKENS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f041e64-3bb6-45ee-a1bd-0b572d3fecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKENS.term_str.value_counts().to_frame('n')\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB['n'] / VOCAB['n'].sum()\n",
    "VOCAB['s'] = 1 / VOCAB['p']\n",
    "VOCAB['i'] = np.log2(VOCAB['s']) \n",
    "VOCAB['h'] = VOCAB['p'] * VOCAB['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4e76e-1c9a-42f7-8ffa-85410bc887d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.to_csv('data/LIB.csv', sep='|')\n",
    "TOKENS.to_csv('data/TOKENS.csv', sep='|')\n",
    "VOCAB.to_csv('data/VOCAB.csv', sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
