{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52dfd6b-aee7-4e79-b8c0-278b05639821",
   "metadata": {},
   "source": [
    "# Creating LIB, CORPUS, and VOCAB tables\n",
    "\n",
    "Charlie Perez (cwp5xyj)\n",
    "\n",
    "A note that the process of clipping the text files and creating the LIB table will be largely done by hand - I really want to preserve things like the Table of Contents for later work (given Martin's writing style, the exact POV of the chapter is important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c49dcf16-b934-4cc6-b4c9-7cb5b61b5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px\n",
    "import configparser\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8945aa6-53d2-4885-9ab4-3b9e75f274b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96a213fa-e3c9-4da1-8377-f4ab5d24b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think I will have to remove Fire and Blood - it wouldn't match well anyways, and would be much more of a novelty\n",
    "\n",
    "metadata = [\n",
    "    {\n",
    "        'ID': 1,\n",
    "        'file': 'agot.txt',\n",
    "        'title': 'A Game of Thrones',\n",
    "        'clip_range': (212, 14145),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (20, 165)\n",
    "    },\n",
    "    {\n",
    "        'ID': 2,\n",
    "        'file': 'acok.txt',\n",
    "        'title': 'A Clash of Kings',\n",
    "        'clip_range': (382, 16150),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (55, 334)\n",
    "    },\n",
    "    {\n",
    "        'ID': 3,\n",
    "        'file': 'asos.txt',\n",
    "        'title': 'A Storm of Swords',\n",
    "        'clip_range': (451, 20253),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (59, 386)\n",
    "    },\n",
    "    {\n",
    "        'ID': 4,\n",
    "        'file': 'affc.txt',\n",
    "        'title': 'A Feast for Crows',\n",
    "        'clip_range': (343, 13963),\n",
    "        'chap_regex': r\"^[A-Z’‘ʼ' ]+$\",\n",
    "        'TOC_range': (87, 271)\n",
    "    },\n",
    "    {\n",
    "        'ID': 5,\n",
    "        'file': 'adwd.txt',\n",
    "        'title': 'A Dance with Dragons',\n",
    "        'clip_range': (344, 18874),\n",
    "        'chap_regex': r\"^[A-Z’‘ʼ' ]+$\",\n",
    "        'TOC_range': (104, 250)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349dc8a-982a-42a6-94c1-332fe3d4a561",
   "metadata": {},
   "source": [
    "#### Create LIB table\n",
    "\n",
    "With formatted table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "454f7139-480a-4d3e-b072-5d106089cfa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'{os.getcwd()}/data'\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d007f0c4-96b2-4e4e-ae66-a5cb6407c298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>clip_range</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>TOC_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "      <td>(212, 14145)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(20, 165)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Clash of Kings</td>\n",
       "      <td>(382, 16150)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(55, 334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Storm of Swords</td>\n",
       "      <td>(451, 20253)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(59, 386)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Feast for Crows</td>\n",
       "      <td>(343, 13963)</td>\n",
       "      <td>^[A-Z’‘ʼ' ]+$</td>\n",
       "      <td>(87, 271)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "      <td>(344, 18874)</td>\n",
       "      <td>^[A-Z’‘ʼ' ]+$</td>\n",
       "      <td>(104, 250)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file                 title  \\\n",
       "ID                                                                            \n",
       "1   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Game of Thrones   \n",
       "2   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...      A Clash of Kings   \n",
       "3   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Storm of Swords   \n",
       "4   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Feast for Crows   \n",
       "5   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...  A Dance with Dragons   \n",
       "\n",
       "      clip_range     chap_regex   TOC_range  \n",
       "ID                                           \n",
       "1   (212, 14145)      ^[A-Z ]+$   (20, 165)  \n",
       "2   (382, 16150)      ^[A-Z ]+$   (55, 334)  \n",
       "3   (451, 20253)      ^[A-Z ]+$   (59, 386)  \n",
       "4   (343, 13963)  ^[A-Z’‘ʼ' ]+$   (87, 271)  \n",
       "5   (344, 18874)  ^[A-Z’‘ʼ' ]+$  (104, 250)  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB = pd.DataFrame(metadata)\n",
    "LIB.file = data_dir + '/' + LIB.file\n",
    "LIB.set_index('ID', inplace=True)\n",
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a853a75-16c1-4f68-8730-27ab0e6d9b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/agot.txt (212, 14145) ^[A-Z ]+$ (20, 165)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/acok.txt (382, 16150) ^[A-Z ]+$ (55, 334)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/asos.txt (451, 20253) ^[A-Z ]+$ (59, 386)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/affc.txt (343, 13963) ^[A-Z’‘ʼ' ]+$ (87, 271)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/adwd.txt (344, 18874) ^[A-Z’‘ʼ' ]+$ (104, 250)\n"
     ]
    }
   ],
   "source": [
    "for idx, row in LIB.iterrows():\n",
    "    src, clip_range, chap_regex, TOC_range = row.file, row.clip_range, row.chap_regex, row.TOC_range\n",
    "    print(src, clip_range, chap_regex, TOC_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5eeb19b-ac32-4c1a-8011-1ee572da37a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_lines(src):\n",
    "    text_lines = open(src,'r', encoding= 'utf-8').readlines()\n",
    "    LINES = pd.DataFrame({'line_str':text_lines})\n",
    "    LINES.index.name = 'line_id'\n",
    "    return LINES\n",
    "\n",
    "def extract_TOC(LINES, TOC_range):\n",
    "    TOC_lines = LINES.loc[TOC_range[0]:TOC_range[1]].copy()\n",
    "    contents = []\n",
    "    chapter_counts = defaultdict(int)\n",
    "    for i in TOC_lines.line_str.str.strip('\\n'):\n",
    "        if i != '':\n",
    "            if i != 'Prologue' and i != 'Epilogue':\n",
    "                chapter_counts[i] += 1\n",
    "                contents.append(f'{i} {chapter_counts[i]}')\n",
    "            else:\n",
    "                contents.append(i)\n",
    "    return contents\n",
    "\n",
    "def parse_tokens(LINES, clip_range, chap_regex, book_id):\n",
    "    LINES = LINES.loc[clip_range[0]:clip_range[1]].copy()\n",
    "    OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "    \n",
    "    LINES.line_str = LINES.line_str.str.replace(r'\\n+', ' ', regex=True).str.strip()\n",
    "    chap_lines = LINES.line_str.str.match(chap_regex)\n",
    "\n",
    "    LINES.loc[chap_lines, 'chap_num'] = [i+1 for i in range(LINES.loc[chap_lines].shape[0])]\n",
    "    LINES.chap_num = LINES.chap_num.ffill()\n",
    "\n",
    "    LINES = LINES.dropna(subset=['chap_num'])\n",
    "    LINES = LINES.loc[~chap_lines]\n",
    "    LINES.chap_num = LINES.chap_num.astype('int')\n",
    "\n",
    "    CHAPS = LINES.groupby(OHCO[:1])\\\n",
    "        .line_str.apply(lambda x: '\\n'.join(x))\\\n",
    "        .to_frame('chap_str')\n",
    "\n",
    "    CHAPS['chap_str'] = CHAPS.chap_str.str.strip()\n",
    "\n",
    "    para_pat = r'\\n\\n+'\n",
    "\n",
    "    PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "        .to_frame('para_str').sort_index()\n",
    "    PARAS.index.names = OHCO[:2]\n",
    "\n",
    "    PARAS['para_str'] = PARAS['para_str'].str.replace(r'\\n', ' ', regex=True)\n",
    "    PARAS['para_str'] = PARAS['para_str'].str.strip()\n",
    "    PARAS = PARAS[~PARAS['para_str'].str.match(r'^\\s*$')]\n",
    "\n",
    "    SENTS = PARAS.para_str\\\n",
    "                    .apply(lambda x: pd.Series(nltk.sent_tokenize(x), dtype='string'))\\\n",
    "                    .stack()\\\n",
    "                    .to_frame('sent_str')\n",
    "\n",
    "    SENTS.index.names = OHCO[:3]\n",
    "\n",
    "    TOKENS = SENTS.sent_str\\\n",
    "                    .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\n",
    "    TOKENS = TOKENS.stack().to_frame('pos_tuple')\n",
    "    TOKENS['pos'] = TOKENS.pos_tuple.apply(lambda x: x[1])\n",
    "    TOKENS['token_str'] = TOKENS.pos_tuple.apply(lambda x: x[0])\n",
    "    TOKENS['term_str'] = TOKENS.token_str.str.lower()\n",
    "\n",
    "    TOKENS.index.names = OHCO[:4]\n",
    "    \n",
    "    TOKENS.reset_index(inplace=True)\n",
    "    TOKENS['book_id'] = book_id\n",
    "    OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "    TOKENS.set_index(OHCO, inplace=True)\n",
    "    \n",
    "    punc_pos = ['$', \"''\", '(', ')', ',', '--', '.', ':', '``']\n",
    "    TOKENS['term_str'] = TOKENS[~TOKENS.pos.isin(punc_pos)].token_str\\\n",
    "                        .str.replace(r'[\\W_]+', '', regex=True).str.lower()  \n",
    "    return TOKENS\n",
    "    \n",
    "    \n",
    "def parse_corpus(LIB):\n",
    "    contents = []\n",
    "    TOKENS = pd.DataFrame()\n",
    "    for idx, row in LIB.iterrows():\n",
    "        book_id, src, clip_range, chap_regex, TOC_range = idx, row.file, row.clip_range, row.chap_regex, row.TOC_range\n",
    "        LINES = read_lines(src)\n",
    "        ind_contents = extract_TOC(LINES, TOC_range)\n",
    "        ind_TOKENS = parse_tokens(LINES, clip_range, chap_regex, book_id)\n",
    "        \n",
    "        contents.append(ind_contents)\n",
    "        TOKENS = pd.concat([TOKENS, ind_TOKENS])\n",
    "    \n",
    "    return contents, TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1feff6b-d2ba-4c3c-a40e-c331442d68a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04221694-2d76-45e9-958b-9ecd3deba6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 619 ms, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "contents, TOKENS = parse_corpus(LIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "787ba574-3ebb-4ec5-87f6-ec04163946b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(“, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>“</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(We, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>We</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(should, MD)</td>\n",
       "      <td>MD</td>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(start, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(back, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                \n",
       "1       1        0        0        0               (“, IN)   IN         “   \n",
       "                                   1             (We, PRP)  PRP        We   \n",
       "                                   2          (should, MD)   MD    should   \n",
       "                                   3           (start, VB)   VB     start   \n",
       "                                   4            (back, RB)   RB      back   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "1       1        0        0        0                   \n",
       "                                   1               we  \n",
       "                                   2           should  \n",
       "                                   3            start  \n",
       "                                   4             back  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4528de05-bdbd-48a6-8dcd-774e53d68cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">73</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">140</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>3</th>\n",
       "      <td>(hands, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>hands</td>\n",
       "      <td>hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(,, ,)</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(daggers, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>daggers</td>\n",
       "      <td>daggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(., .)</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                  \n",
       "5       73       140      0        3            (hands, NNS)  NNS     hands   \n",
       "                                   4                  (,, ,)    ,         ,   \n",
       "                                   5               (the, DT)   DT       the   \n",
       "                                   6          (daggers, NNS)  NNS   daggers   \n",
       "                                   7                  (., .)    .         .   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "5       73       140      0        3            hands  \n",
       "                                   4              NaN  \n",
       "                                   5              the  \n",
       "                                   6          daggers  \n",
       "                                   7              NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64e3f423-8410-4e91-a61f-0502e4998381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id\n",
       "1    73\n",
       "2    70\n",
       "3    82\n",
       "4    46\n",
       "5    73\n",
       "Name: chap_num, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.reset_index()[['book_id','chap_num']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_id').chap_num.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe20d78e-1fca-4653-b0d3-da7fdb6044d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 70, 82, 46, 73]\n"
     ]
    }
   ],
   "source": [
    "print([len(i) for i in contents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31085e7-4baa-47bc-98cd-16c24e328f88",
   "metadata": {},
   "source": [
    "Need to manually mess with the AFFC and ADWD chapters - gonna be a bit of a pain\n",
    "\n",
    "Session died. Tears. Not gonna reload everything right now.\n",
    "\n",
    "#### Create Vocabulary from TOKENS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f041e64-3bb6-45ee-a1bd-0b572d3fecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = TOKENS # forgot it was supposed to be called CORPUS\n",
    "CORPUS = CORPUS[CORPUS.term_str != ''].copy() # get rid of random punctuation\n",
    "CORPUS['pos_group'] = CORPUS.pos.str[:2] # also didn't realize this was needed too\n",
    "\n",
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n')\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['p'] = VOCAB['n'] / VOCAB['n'].sum()\n",
    "VOCAB['s'] = 1 / VOCAB['p']\n",
    "VOCAB['i'] = np.log2(VOCAB['s']) \n",
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba18577c-3c91-495f-9e2d-379ecb8ab3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add features\n",
    "LIB['date'] = [1996, 1998, 2000, 2005, 2011]\n",
    "LIB['chap_labels'] = contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d61ed0-fca6-4735-914a-b31d5ba1e1b3",
   "metadata": {},
   "source": [
    "I understand that I'm short some metadata (I contemplated branching out into other book series, or a different type of ASOIAF books). But I like what I have going on here and am disinclined to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cee4e76e-1c9a-42f7-8ffa-85410bc887d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these two as they likely won't be changed again\n",
    "\n",
    "LIB.to_csv('output/LIB.csv', sep='|')\n",
    "CORPUS.to_csv('output/CORPUS.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b8818-2d15-4177-8dee-ec75f84995e5",
   "metadata": {},
   "source": [
    "#### Getting into BOW, TFIDF, and DFIDF\n",
    "\n",
    "No point keeping these separate. Need DFIDF in the VOCAB table, so may as well do it here.\n",
    "\n",
    "Chapter is the unit of observation most interesting to me, so that's what we're gonna go with here. TF method is 'sum' and IDF method is 'standard'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d14c48d3-ba9c-4631-baa2-58bbf9af7886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag = ['book_id', 'chap_num']\n",
    "BOW = CORPUS.groupby(bag+['term_str']).term_str.count().to_frame('n')\n",
    "DTCM = BOW.n.unstack(fill_value=0)\n",
    "N = DTCM.shape[0]\n",
    "TF = (DTCM.T / DTCM.T.sum()).T\n",
    "DF = DTCM.astype('bool').sum()\n",
    "IDF = np.log2(N / DF)\n",
    "TFIDF = TF * IDF\n",
    "\n",
    "VOCAB['df'] = DF\n",
    "VOCAB['dfidf'] = VOCAB.df * np.log2(len(TFIDF)/VOCAB.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "00bb5f2b-8b81-428b-97a6-f878b498cabb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>df</th>\n",
       "      <th>dfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lannisters</th>\n",
       "      <td>310</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5693.232258</td>\n",
       "      <td>12.475032</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>127</td>\n",
       "      <td>182.572669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whilst</th>\n",
       "      <td>286</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>6170.986014</td>\n",
       "      <td>12.591285</td>\n",
       "      <td>NN</td>\n",
       "      <td>VB</td>\n",
       "      <td>127</td>\n",
       "      <td>182.572669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laughing</th>\n",
       "      <td>183</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>9644.273224</td>\n",
       "      <td>13.235457</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>127</td>\n",
       "      <td>182.572669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frowned</th>\n",
       "      <td>155</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>11386.464516</td>\n",
       "      <td>13.475032</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>127</td>\n",
       "      <td>182.572669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fist</th>\n",
       "      <td>231</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>7640.268398</td>\n",
       "      <td>12.899408</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>127</td>\n",
       "      <td>182.572669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn</th>\n",
       "      <td>275</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>6417.825455</td>\n",
       "      <td>12.647869</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>127</td>\n",
       "      <td>182.572669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>177</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>9971.197740</td>\n",
       "      <td>13.283551</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorry</th>\n",
       "      <td>189</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>9338.105820</td>\n",
       "      <td>13.188914</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stupid</th>\n",
       "      <td>253</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>6975.897233</td>\n",
       "      <td>12.768163</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fires</th>\n",
       "      <td>221</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>7985.981900</td>\n",
       "      <td>12.963254</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaving</th>\n",
       "      <td>167</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>10568.275449</td>\n",
       "      <td>13.367452</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weak</th>\n",
       "      <td>189</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>9338.105820</td>\n",
       "      <td>13.188914</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stared</th>\n",
       "      <td>165</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>10696.375758</td>\n",
       "      <td>13.384834</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maybe</th>\n",
       "      <td>291</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>6064.955326</td>\n",
       "      <td>12.566281</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaves</th>\n",
       "      <td>244</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>7233.204918</td>\n",
       "      <td>12.820419</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doors</th>\n",
       "      <td>235</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>7510.221277</td>\n",
       "      <td>12.874640</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>182.572089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>172</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>10261.058140</td>\n",
       "      <td>13.324892</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>128</td>\n",
       "      <td>182.561889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flames</th>\n",
       "      <td>353</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4999.722380</td>\n",
       "      <td>12.287632</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>128</td>\n",
       "      <td>182.561889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift</th>\n",
       "      <td>252</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>7003.579365</td>\n",
       "      <td>12.773877</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>128</td>\n",
       "      <td>182.561889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quite</th>\n",
       "      <td>201</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>8780.606965</td>\n",
       "      <td>13.100105</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>128</td>\n",
       "      <td>182.561889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              n         p             s          i max_pos max_pos_group   df  \\\n",
       "term_str                                                                        \n",
       "lannisters  310  0.000176   5693.232258  12.475032     NNP            NN  127   \n",
       "whilst      286  0.000162   6170.986014  12.591285      NN            VB  127   \n",
       "laughing    183  0.000104   9644.273224  13.235457     VBG            VB  127   \n",
       "frowned     155  0.000088  11386.464516  13.475032     VBD            VB  127   \n",
       "fist        231  0.000131   7640.268398  12.899408      NN            NN  127   \n",
       "didn        275  0.000156   6417.825455  12.647869     VBP            VB  127   \n",
       "recall      177  0.000100   9971.197740  13.283551      VB            VB  126   \n",
       "sorry       189  0.000107   9338.105820  13.188914      JJ            JJ  126   \n",
       "stupid      253  0.000143   6975.897233  12.768163      JJ            JJ  126   \n",
       "fires       221  0.000125   7985.981900  12.963254     NNS            NN  126   \n",
       "leaving     167  0.000095  10568.275449  13.367452     VBG            VB  126   \n",
       "weak        189  0.000107   9338.105820  13.188914      JJ            JJ  126   \n",
       "stared      165  0.000093  10696.375758  13.384834     VBD            VB  126   \n",
       "maybe       291  0.000165   6064.955326  12.566281      RB            RB  126   \n",
       "leaves      244  0.000138   7233.204918  12.820419     NNS            NN  126   \n",
       "doors       235  0.000133   7510.221277  12.874640     NNS            NN  126   \n",
       "lead        172  0.000097  10261.058140  13.324892      VB            VB  128   \n",
       "flames      353  0.000200   4999.722380  12.287632     NNS            NN  128   \n",
       "gift        252  0.000143   7003.579365  12.773877      NN            NN  128   \n",
       "quite       201  0.000114   8780.606965  13.100105      RB            RB  128   \n",
       "\n",
       "                 dfidf  \n",
       "term_str                \n",
       "lannisters  182.572669  \n",
       "whilst      182.572669  \n",
       "laughing    182.572669  \n",
       "frowned     182.572669  \n",
       "fist        182.572669  \n",
       "didn        182.572669  \n",
       "recall      182.572089  \n",
       "sorry       182.572089  \n",
       "stupid      182.572089  \n",
       "fires       182.572089  \n",
       "leaving     182.572089  \n",
       "weak        182.572089  \n",
       "stared      182.572089  \n",
       "maybe       182.572089  \n",
       "leaves      182.572089  \n",
       "doors       182.572089  \n",
       "lead        182.561889  \n",
       "flames      182.561889  \n",
       "gift        182.561889  \n",
       "quite       182.561889  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sort_values(by='dfidf', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c3f3966-c631-43b3-8b26-db2ba9a6f6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now for stemming and stopwords\n",
    "\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "\n",
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "58864bcd-8342-461a-9d22-ab0d57c4cd39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>df</th>\n",
       "      <th>dfidf</th>\n",
       "      <th>stop</th>\n",
       "      <th>porter_stem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>101699</td>\n",
       "      <td>0.057623</td>\n",
       "      <td>17.354173</td>\n",
       "      <td>4.117211</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>51225</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>34.453919</td>\n",
       "      <td>5.106596</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>39497</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>44.684457</td>\n",
       "      <td>5.481701</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "      <td>344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>39269</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>44.943900</td>\n",
       "      <td>5.490053</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>35196</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>50.144960</td>\n",
       "      <td>5.648033</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               n         p          s         i max_pos max_pos_group   df  \\\n",
       "term_str                                                                     \n",
       "the       101699  0.057623  17.354173  4.117211      DT            DT  344   \n",
       "and        51225  0.029024  34.453919  5.106596      CC            CC  344   \n",
       "to         39497  0.022379  44.684457  5.481701      TO            TO  344   \n",
       "a          39269  0.022250  44.943900  5.490053      DT            DT  344   \n",
       "of         35196  0.019942  50.144960  5.648033      IN            IN  344   \n",
       "\n",
       "          dfidf  stop porter_stem  \n",
       "term_str                           \n",
       "the         0.0     1         the  \n",
       "and         0.0     1         and  \n",
       "to          0.0     1          to  \n",
       "a           0.0     1           a  \n",
       "of          0.0     1          of  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['porter_stem'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)\n",
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00e99ab9-21bb-49c0-99f6-571be4f52553",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv('output/VOCAB.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f98983b5-c181-47c3-9b2e-bd0b65ed7aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th>a</th>\n",
       "      <td>111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>above</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accustomed</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquiescence</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>across</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjusted</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admitted</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aemon</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 n     tfidf\n",
       "book_id chap_num term_str                   \n",
       "1       1        a             111  0.000000\n",
       "                 abandoned       2  0.001161\n",
       "                 about           4  0.000053\n",
       "                 above           1  0.000120\n",
       "                 accustomed      1  0.000878\n",
       "                 acquiescence    1  0.002188\n",
       "                 across          1  0.000026\n",
       "                 adjusted        1  0.001409\n",
       "                 admitted        1  0.000463\n",
       "                 aemon           2  0.001260"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the BOW, DCTM, and TFIDF matrices\n",
    "\n",
    "BOW['tfidf'] = TFIDF.stack()\n",
    "\n",
    "BOW.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40364ce1-ac8e-4806-8df1-688e372003b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>10th</th>\n",
       "      <th>15th</th>\n",
       "      <th>16th</th>\n",
       "      <th>23rd</th>\n",
       "      <th>57th</th>\n",
       "      <th>61st</th>\n",
       "      <th>a</th>\n",
       "      <th>aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee</th>\n",
       "      <th>aaaaaaoooooooooooooooooooooooo</th>\n",
       "      <th>aaaaahoooooooooooooooooooo</th>\n",
       "      <th>...</th>\n",
       "      <th>zekko</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zhak</th>\n",
       "      <th>zharaq</th>\n",
       "      <th>zigged</th>\n",
       "      <th>zo</th>\n",
       "      <th>zollo</th>\n",
       "      <th>zorse</th>\n",
       "      <th>zorses</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str          10th  15th  16th  23rd  57th  61st    a  \\\n",
       "book_id chap_num                                            \n",
       "1       1            0     0     0     0     0     0  111   \n",
       "        2            0     0     0     0     0     0   63   \n",
       "        3            0     0     0     0     0     0   41   \n",
       "        4            0     0     0     0     0     0   78   \n",
       "        5            0     0     0     0     0     0   86   \n",
       "\n",
       "term_str          aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee  \\\n",
       "book_id chap_num                                                          \n",
       "1       1                                                         0       \n",
       "        2                                                         0       \n",
       "        3                                                         0       \n",
       "        4                                                         0       \n",
       "        5                                                         0       \n",
       "\n",
       "term_str          aaaaaaoooooooooooooooooooooooo  aaaaahoooooooooooooooooooo  \\\n",
       "book_id chap_num                                                               \n",
       "1       1                                      0                           0   \n",
       "        2                                      0                           0   \n",
       "        3                                      0                           0   \n",
       "        4                                      0                           0   \n",
       "        5                                      0                           0   \n",
       "\n",
       "term_str          ...  zekko  zenith  zhak  zharaq  zigged  zo  zollo  zorse  \\\n",
       "book_id chap_num  ...                                                          \n",
       "1       1         ...      0       0     0       0       0   0      0      0   \n",
       "        2         ...      0       0     0       0       0   0      0      0   \n",
       "        3         ...      0       0     0       0       0   0      0      0   \n",
       "        4         ...      0       0     0       0       0   0      0      0   \n",
       "        5         ...      0       0     0       0       0   0      0      0   \n",
       "\n",
       "term_str          zorses  zzzs  \n",
       "book_id chap_num                \n",
       "1       1              0     0  \n",
       "        2              0     0  \n",
       "        3              0     0  \n",
       "        4              0     0  \n",
       "        5              0     0  \n",
       "\n",
       "[5 rows x 24235 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTCM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6d849-29f0-43b7-a1cb-2680de06e2ca",
   "metadata": {},
   "source": [
    "It may look like there's an issue with the source material, but there are actually just several different horn sounds in one particular chapter in *A Feast for Crows*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ebaabbda-5f8f-4cc0-9c0b-54692189e64a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>10th</th>\n",
       "      <th>15th</th>\n",
       "      <th>16th</th>\n",
       "      <th>23rd</th>\n",
       "      <th>57th</th>\n",
       "      <th>61st</th>\n",
       "      <th>a</th>\n",
       "      <th>aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee</th>\n",
       "      <th>aaaaaaoooooooooooooooooooooooo</th>\n",
       "      <th>aaaaahoooooooooooooooooooo</th>\n",
       "      <th>...</th>\n",
       "      <th>zekko</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zhak</th>\n",
       "      <th>zharaq</th>\n",
       "      <th>zigged</th>\n",
       "      <th>zo</th>\n",
       "      <th>zollo</th>\n",
       "      <th>zorse</th>\n",
       "      <th>zorses</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str          10th  15th  16th  23rd  57th  61st    a  \\\n",
       "book_id chap_num                                            \n",
       "1       1          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        2          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        3          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        4          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        5          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "term_str          aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee  \\\n",
       "book_id chap_num                                                          \n",
       "1       1                                                       0.0       \n",
       "        2                                                       0.0       \n",
       "        3                                                       0.0       \n",
       "        4                                                       0.0       \n",
       "        5                                                       0.0       \n",
       "\n",
       "term_str          aaaaaaoooooooooooooooooooooooo  aaaaahoooooooooooooooooooo  \\\n",
       "book_id chap_num                                                               \n",
       "1       1                                    0.0                         0.0   \n",
       "        2                                    0.0                         0.0   \n",
       "        3                                    0.0                         0.0   \n",
       "        4                                    0.0                         0.0   \n",
       "        5                                    0.0                         0.0   \n",
       "\n",
       "term_str          ...  zekko  zenith  zhak  zharaq  zigged   zo  zollo  zorse  \\\n",
       "book_id chap_num  ...                                                           \n",
       "1       1         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        2         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        3         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        4         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        5         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "\n",
       "term_str          zorses  zzzs  \n",
       "book_id chap_num                \n",
       "1       1            0.0   0.0  \n",
       "        2            0.0   0.0  \n",
       "        3            0.0   0.0  \n",
       "        4            0.0   0.0  \n",
       "        5            0.0   0.0  \n",
       "\n",
       "[5 rows x 24235 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f1462-dc20-4094-aa70-2b0b7616c65d",
   "metadata": {},
   "source": [
    "So I am guessing that \"reduced and normalized TFIDF_L2\" means I have to reduce it to some specific feature size, probably by DFIDF.\n",
    "\n",
    "I think I want to take out proper nouns (names) but probably keep verbs and adjectives? Is 5000 too many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c571313-b0b9-47f2-9b56-345fdbb4ade3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VSHORT = VOCAB[VOCAB.max_pos_group.isin(['NN', 'VB', 'JJ']) & ~VOCAB.max_pos.isin(['NNP'])].sort_values('dfidf', ascending=False).head(2000)\n",
    "\n",
    "TFIDF_2000 = TFIDF[VSHORT.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c5db9ef-bfeb-444d-9f72-51cac64ec01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74d3bf28-5666-4e6d-8caa-9c0466773372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TFIDF_L2\n",
    "\n",
    "TFIDF_L2 = (TFIDF_2000.T / norm(TFIDF_2000, 2, axis=1)).T\n",
    "\n",
    "a = len(TFIDF_L2)\n",
    "TFIDF_L2 = TFIDF_L2.dropna()\n",
    "b = len(TFIDF_L2)\n",
    "bag_loss = a - b\n",
    "bag_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9255b5c0-f899-41d5-9511-9b34fb024982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>didn</th>\n",
       "      <th>whilst</th>\n",
       "      <th>laughing</th>\n",
       "      <th>fist</th>\n",
       "      <th>frowned</th>\n",
       "      <th>doors</th>\n",
       "      <th>sorry</th>\n",
       "      <th>stupid</th>\n",
       "      <th>leaving</th>\n",
       "      <th>leaves</th>\n",
       "      <th>...</th>\n",
       "      <th>quicker</th>\n",
       "      <th>shuddered</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>height</th>\n",
       "      <th>honorable</th>\n",
       "      <th>trimmed</th>\n",
       "      <th>freedom</th>\n",
       "      <th>pressing</th>\n",
       "      <th>consider</th>\n",
       "      <th>uncomfortable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>69</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048142</td>\n",
       "      <td>0.032094</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048524</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str              didn    whilst  laughing      fist   frowned     doors  \\\n",
       "book_id chap_num                                                               \n",
       "1       1         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "        2         0.029764  0.000000  0.059528  0.000000  0.029764  0.000000   \n",
       "        3         0.000000  0.000000  0.000000  0.000000  0.031174  0.000000   \n",
       "        4         0.000000  0.000000  0.000000  0.000000  0.000000  0.043713   \n",
       "        5         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "5       69        0.000000  0.014151  0.000000  0.000000  0.000000  0.142629   \n",
       "        70        0.000000  0.048142  0.032094  0.016047  0.000000  0.048524   \n",
       "        71        0.000000  0.030067  0.000000  0.045100  0.000000  0.000000   \n",
       "        72        0.000000  0.000000  0.009752  0.019504  0.000000  0.000000   \n",
       "        73        0.000000  0.052250  0.000000  0.017417  0.000000  0.000000   \n",
       "\n",
       "term_str             sorry   stupid   leaving    leaves  ...   quicker  \\\n",
       "book_id chap_num                                         ...             \n",
       "1       1         0.000000  0.00000  0.000000  0.071728  ...  0.000000   \n",
       "        2         0.000000  0.00000  0.000000  0.000000  ...  0.000000   \n",
       "        3         0.031421  0.00000  0.000000  0.031421  ...  0.000000   \n",
       "        4         0.000000  0.00000  0.000000  0.043713  ...  0.000000   \n",
       "        5         0.000000  0.00000  0.028599  0.000000  ...  0.000000   \n",
       "...                    ...      ...       ...       ...  ...       ...   \n",
       "5       69        0.000000  0.00000  0.000000  0.000000  ...  0.061834   \n",
       "        70        0.032349  0.00000  0.000000  0.000000  ...  0.000000   \n",
       "        71        0.000000  0.00000  0.000000  0.000000  ...  0.000000   \n",
       "        72        0.000000  0.00983  0.000000  0.009830  ...  0.000000   \n",
       "        73        0.035110  0.00000  0.000000  0.000000  ...  0.000000   \n",
       "\n",
       "term_str          shuddered  knowledge    height  honorable   trimmed  \\\n",
       "book_id chap_num                                                        \n",
       "1       1          0.000000        0.0  0.000000   0.000000  0.000000   \n",
       "        2          0.000000        0.0  0.000000   0.000000  0.065029   \n",
       "        3          0.000000        0.0  0.000000   0.000000  0.000000   \n",
       "        4          0.000000        0.0  0.000000   0.047377  0.000000   \n",
       "        5          0.000000        0.0  0.061991   0.000000  0.000000   \n",
       "...                     ...        ...       ...        ...       ...   \n",
       "5       69         0.000000        0.0  0.000000   0.000000  0.000000   \n",
       "        70         0.000000        0.0  0.000000   0.000000  0.035060   \n",
       "        71         0.000000        0.0  0.000000   0.000000  0.000000   \n",
       "        72         0.000000        0.0  0.000000   0.000000  0.000000   \n",
       "        73         0.038053        0.0  0.000000   0.000000  0.000000   \n",
       "\n",
       "term_str           freedom  pressing  consider  uncomfortable  \n",
       "book_id chap_num                                               \n",
       "1       1         0.000000  0.000000  0.000000            0.0  \n",
       "        2         0.000000  0.000000  0.000000            0.0  \n",
       "        3         0.000000  0.000000  0.000000            0.0  \n",
       "        4         0.000000  0.000000  0.000000            0.0  \n",
       "        5         0.000000  0.061991  0.061991            0.0  \n",
       "...                    ...       ...       ...            ...  \n",
       "5       69        0.000000  0.000000  0.000000            0.0  \n",
       "        70        0.000000  0.000000  0.000000            0.0  \n",
       "        71        0.000000  0.032845  0.000000            0.0  \n",
       "        72        0.021307  0.000000  0.000000            0.0  \n",
       "        73        0.000000  0.038053  0.000000            0.0  \n",
       "\n",
       "[344 rows x 2000 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a7f7b63e-45a3-47ba-9a69-61727d67fb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOW.to_csv('output/BOW.csv', sep='|')\n",
    "DTCM.to_csv('output/DTM.csv', sep='|')\n",
    "TFIDF.to_csv('output/TFIDF.csv', sep='|')\n",
    "TFIDF_L2.to_csv('output/TFIDF_L2.csv', sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
