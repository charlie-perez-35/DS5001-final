{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52dfd6b-aee7-4e79-b8c0-278b05639821",
   "metadata": {},
   "source": [
    "# Creating LIB, CORPUS, and VOCAB tables\n",
    "\n",
    "Charlie Perez (cwp5xyj)\n",
    "\n",
    "A note that the process of clipping the text files and creating the LIB table will be largely done by hand - I really want to preserve things like the Table of Contents for later work (given Martin's writing style, the exact POV of the chapter is important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49dcf16-b934-4cc6-b4c9-7cb5b61b5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px\n",
    "import configparser\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8945aa6-53d2-4885-9ab4-3b9e75f274b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a213fa-e3c9-4da1-8377-f4ab5d24b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think I will have to remove Fire and Blood - it wouldn't match well anyways, and would be much more of a novelty\n",
    "\n",
    "metadata = [\n",
    "    {\n",
    "        'ID': 1,\n",
    "        'file': 'agot.txt',\n",
    "        'title': 'A Game of Thrones',\n",
    "        'clip_range': (212, 14145),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (20, 165)\n",
    "    },\n",
    "    {\n",
    "        'ID': 2,\n",
    "        'file': 'acok.txt',\n",
    "        'title': 'A Clash of Kings',\n",
    "        'clip_range': (382, 16150),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (55, 334)\n",
    "    },\n",
    "    {\n",
    "        'ID': 3,\n",
    "        'file': 'asos.txt',\n",
    "        'title': 'A Storm of Swords',\n",
    "        'clip_range': (451, 20253),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (59, 386)\n",
    "    },\n",
    "    {\n",
    "        'ID': 4,\n",
    "        'file': 'affc.txt',\n",
    "        'title': 'A Feast for Crows',\n",
    "        'clip_range': (343, 13963),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (87, 271)\n",
    "    },\n",
    "    {\n",
    "        'ID': 5,\n",
    "        'file': 'adwd.txt',\n",
    "        'title': 'A Dance with Dragons',\n",
    "        'clip_range': (344, 18874),\n",
    "        'chap_regex': r'^[A-Z ]+$',\n",
    "        'TOC_range': (104, 250)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349dc8a-982a-42a6-94c1-332fe3d4a561",
   "metadata": {},
   "source": [
    "#### Create LIB table\n",
    "\n",
    "With formatted table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454f7139-480a-4d3e-b072-5d106089cfa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'{os.getcwd()}/data'\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d007f0c4-96b2-4e4e-ae66-a5cb6407c298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>clip_range</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>TOC_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Game of Thrones</td>\n",
       "      <td>(212, 14145)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(20, 165)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Clash of Kings</td>\n",
       "      <td>(382, 16150)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(55, 334)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Storm of Swords</td>\n",
       "      <td>(451, 20253)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(59, 386)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Feast for Crows</td>\n",
       "      <td>(343, 13963)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(87, 271)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...</td>\n",
       "      <td>A Dance with Dragons</td>\n",
       "      <td>(344, 18874)</td>\n",
       "      <td>^[A-Z ]+$</td>\n",
       "      <td>(104, 250)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file                 title  \\\n",
       "ID                                                                            \n",
       "1   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Game of Thrones   \n",
       "2   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...      A Clash of Kings   \n",
       "3   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Storm of Swords   \n",
       "4   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...     A Feast for Crows   \n",
       "5   /sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/D...  A Dance with Dragons   \n",
       "\n",
       "      clip_range chap_regex   TOC_range  \n",
       "ID                                       \n",
       "1   (212, 14145)  ^[A-Z ]+$   (20, 165)  \n",
       "2   (382, 16150)  ^[A-Z ]+$   (55, 334)  \n",
       "3   (451, 20253)  ^[A-Z ]+$   (59, 386)  \n",
       "4   (343, 13963)  ^[A-Z ]+$   (87, 271)  \n",
       "5   (344, 18874)  ^[A-Z ]+$  (104, 250)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB = pd.DataFrame(metadata)\n",
    "LIB.file = data_dir + '/' + LIB.file\n",
    "LIB.set_index('ID', inplace=True)\n",
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a853a75-16c1-4f68-8730-27ab0e6d9b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/agot.txt (212, 14145) ^[A-Z ]+$ (20, 165)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/acok.txt (382, 16150) ^[A-Z ]+$ (55, 334)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/asos.txt (451, 20253) ^[A-Z ]+$ (59, 386)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/affc.txt (343, 13963) ^[A-Z ]+$ (87, 271)\n",
      "/sfs/gpfs/tardis/home/cwp5xyj/Documents/MSDS/DS5001/final-project/data/adwd.txt (344, 18874) ^[A-Z ]+$ (104, 250)\n"
     ]
    }
   ],
   "source": [
    "for idx, row in LIB.iterrows():\n",
    "    src, clip_range, chap_ragex, TOC_range = row.file, row.clip_range, row.chap_regex, row.TOC_range\n",
    "    print(src, clip_range, chap_ragex, TOC_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5eeb19b-ac32-4c1a-8011-1ee572da37a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_lines(src):\n",
    "    text_lines = open(src,'r', encoding= 'utf-8').readlines()\n",
    "    LINES = pd.DataFrame({'line_str':text_lines})\n",
    "    LINES.index.name = 'line_id'\n",
    "    return LINES\n",
    "\n",
    "def extract_TOC(LINES, TOC_range):\n",
    "    TOC_lines = LINES.loc[TOC_range[0]:TOC_range[1]].copy()\n",
    "    contents = []\n",
    "    chapter_counts = defaultdict(int)\n",
    "    for i in TOC_lines.line_str.str.strip('\\n'):\n",
    "        if i != '':\n",
    "            if i != 'Prologue' and i != 'Epilogue':\n",
    "                chapter_counts[i] += 1\n",
    "                contents.append(f'{i} {chapter_counts[i]}')\n",
    "            else:\n",
    "                contents.append(i)\n",
    "    return contents\n",
    "\n",
    "def parse_tokens(LINES, clip_range, chap_regex, book_id):\n",
    "    LINES = LINES.loc[clip_range[0]:clip_range[1]].copy()\n",
    "    OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "    \n",
    "    LINES.line_str = LINES.line_str.str.replace(r'\\n+', ' ', regex=True).str.strip()\n",
    "    chap_lines = LINES.line_str.str.match(chap_regex, case=False)\n",
    "\n",
    "    LINES.loc[chap_lines, 'chap_num'] = [i+1 for i in range(LINES.loc[chap_lines].shape[0])]\n",
    "    LINES.chap_num = LINES.chap_num.ffill()\n",
    "\n",
    "    LINES = LINES.dropna(subset=['chap_num'])\n",
    "    LINES = LINES.loc[~chap_lines]\n",
    "    LINES.chap_num = LINES.chap_num.astype('int')\n",
    "\n",
    "    CHAPS = LINES.groupby(OHCO[:1])\\\n",
    "        .line_str.apply(lambda x: '\\n'.join(x))\\\n",
    "        .to_frame('chap_str')\n",
    "\n",
    "    CHAPS['chap_str'] = CHAPS.chap_str.str.strip()\n",
    "\n",
    "    para_pat = r'\\n\\n+'\n",
    "\n",
    "    PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "        .to_frame('para_str').sort_index()\n",
    "    PARAS.index.names = OHCO[:2]\n",
    "\n",
    "    PARAS['para_str'] = PARAS['para_str'].str.replace(r'\\n', ' ', regex=True)\n",
    "    PARAS['para_str'] = PARAS['para_str'].str.strip()\n",
    "    PARAS = PARAS[~PARAS['para_str'].str.match(r'^\\s*$')]\n",
    "\n",
    "    SENTS = PARAS.para_str\\\n",
    "                    .apply(lambda x: pd.Series(nltk.sent_tokenize(x), dtype='string'))\\\n",
    "                    .stack()\\\n",
    "                    .to_frame('sent_str')\n",
    "\n",
    "    SENTS.index.names = OHCO[:3]\n",
    "\n",
    "    TOKENS = SENTS.sent_str\\\n",
    "                    .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\n",
    "    TOKENS = TOKENS.stack().to_frame('pos_tuple')\n",
    "    TOKENS['pos'] = TOKENS.pos_tuple.apply(lambda x: x[1])\n",
    "    TOKENS['token_str'] = TOKENS.pos_tuple.apply(lambda x: x[0])\n",
    "    TOKENS['term_str'] = TOKENS.token_str.str.lower()\n",
    "\n",
    "    TOKENS.index.names = OHCO[:4]\n",
    "    \n",
    "    TOKENS.reset_index(inplace=True)\n",
    "    TOKENS['book_id'] = book_id\n",
    "    OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "    TOKENS.set_index(OHCO, inplace=True)\n",
    "    \n",
    "    punc_pos = ['$', \"''\", '(', ')', ',', '--', '.', ':', '``']\n",
    "    TOKENS['term_str'] = TOKENS[~TOKENS.pos.isin(punc_pos)].token_str\\\n",
    "                        .str.replace(r'[\\W_]+', '', regex=True).str.lower()  \n",
    "    return TOKENS\n",
    "    \n",
    "    \n",
    "def parse_corpus(LIB):\n",
    "    contents = []\n",
    "    TOKENS = pd.DataFrame()\n",
    "    for idx, row in LIB.iterrows():\n",
    "        book_id, src, clip_range, chap_regex, TOC_range = idx, row.file, row.clip_range, row.chap_regex, row.TOC_range\n",
    "        LINES = read_lines(src)\n",
    "        ind_contents = extract_TOC(LINES, TOC_range)\n",
    "        ind_TOKENS = parse_tokens(LINES, clip_range, chap_regex, book_id)\n",
    "        \n",
    "        contents.append(ind_contents)\n",
    "        TOKENS = pd.concat([TOKENS, ind_TOKENS])\n",
    "    \n",
    "    return contents, TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1feff6b-d2ba-4c3c-a40e-c331442d68a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04221694-2d76-45e9-958b-9ecd3deba6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 1.24 s, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "contents, TOKENS = parse_corpus(LIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787ba574-3ebb-4ec5-87f6-ec04163946b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(“, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>“</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(We, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>We</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(should, MD)</td>\n",
       "      <td>MD</td>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(start, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(back, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                \n",
       "1       1        0        0        0               (“, IN)   IN         “   \n",
       "                                   1             (We, PRP)  PRP        We   \n",
       "                                   2          (should, MD)   MD    should   \n",
       "                                   3           (start, VB)   VB     start   \n",
       "                                   4            (back, RB)   RB      back   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "1       1        0        0        0                   \n",
       "                                   1               we  \n",
       "                                   2           should  \n",
       "                                   3            start  \n",
       "                                   4             back  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4528de05-bdbd-48a6-8dcd-774e53d68cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">70</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">140</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>3</th>\n",
       "      <td>(hands, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>hands</td>\n",
       "      <td>hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(,, ,)</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(daggers, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>daggers</td>\n",
       "      <td>daggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(., .)</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                  \n",
       "5       70       140      0        3            (hands, NNS)  NNS     hands   \n",
       "                                   4                  (,, ,)    ,         ,   \n",
       "                                   5               (the, DT)   DT       the   \n",
       "                                   6          (daggers, NNS)  NNS   daggers   \n",
       "                                   7                  (., .)    .         .   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "5       70       140      0        3            hands  \n",
       "                                   4              NaN  \n",
       "                                   5              the  \n",
       "                                   6          daggers  \n",
       "                                   7              NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe20d78e-1fca-4653-b0d3-da7fdb6044d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Prologue', 'Bran 1', 'Catelyn 1', 'Daenerys 1', 'Eddard 1', 'Jon 1', 'Catelyn 2', 'Arya 1', 'Bran 2', 'Tyrion 1', 'Jon 2', 'Daenerys 2', 'Eddard 2', 'Tyrion 2', 'Catelyn 3', 'Sansa 1', 'Eddard 3', 'Bran 3', 'Catelyn 4', 'Jon 3', 'Eddard 4', 'Tyrion 3', 'Arya 2', 'Daenerys 3', 'Bran 4', 'Eddard 5', 'Jon 4', 'Eddard 6', 'Catelyn 5', 'Sansa 2', 'Eddard 7', 'Tyrion 4', 'Arya 3', 'Eddard 8', 'Catelyn 6', 'Eddard 9', 'Daenerys 4', 'Bran 5', 'Tyrion 5', 'Eddard 10', 'Catelyn 7', 'Jon 5', 'Tyrion 6', 'Eddard 11', 'Sansa 3', 'Eddard 12', 'Daenerys 5', 'Eddard 13', 'Jon 6', 'Eddard 14', 'Arya 4', 'Sansa 4', 'Jon 7', 'Bran 6', 'Daenerys 6', 'Catelyn 8', 'Tyrion 7', 'Sansa 5', 'Eddard 15', 'Catelyn 9', 'Jon 8', 'Daenerys 7', 'Tyrion 8', 'Catelyn 10', 'Daenerys 8', 'Arya 5', 'Bran 7', 'Sansa 6', 'Daenerys 9', 'Tyrion 9', 'Jon 9', 'Catelyn 11', 'Daenerys 10'], ['PROLOGUE 1', 'ARYA 1', 'SANSA 1', 'TYRION 1', 'BRAN 1', 'ARYA 2', 'JON 1', 'CATELYN 1', 'TYRION 2', 'ARYA 3', 'DAVOS 1', 'THEON 1', 'DAENERYS 1', 'JON 2', 'ARYA 4', 'TYRION 3', 'BRAN 2', 'TYRION 4', 'SANSA 2', 'ARYA 5', 'TYRION 5', 'BRAN 3', 'CATELYN 2', 'JON 3', 'THEON 2', 'TYRION 6', 'ARYA 6', 'DAENERYS 2', 'BRAN 4', 'TYRION 7', 'ARYA 7', 'CATELYN 3', 'SANSA 3', 'CATELYN 4', 'JON 4', 'BRAN 5', 'TYRION 8', 'THEON 3', 'ARYA 8', 'CATELYN 5', 'DAENERYS 3', 'TYRION 9', 'DAVOS 2', 'JON 5', 'TYRION 10', 'CATELYN 6', 'BRAN 6', 'ARYA 9', 'DAENERYS 4', 'TYRION 11', 'THEON 4', 'JON 6', 'SANSA 4', 'JON 7', 'TYRION 12', 'CATELYN 7', 'THEON 5', 'SANSA 5', 'DAVOS 3', 'TYRION 13', 'SANSA 6', 'TYRION 14', 'SANSA 7', 'DAENERYS 5', 'ARYA 10', 'SANSA 8', 'THEON 6', 'TYRION 15', 'JON 8', 'BRAN 7'], ['PROLOGUE 1', 'JAIME 1', 'CATELYN 1', 'ARYA 1', 'TYRION 1', 'DAVOS 1', 'SANSA 1', 'JON 1', 'DAENERYS 1', 'BRAN 1', 'DAVOS 2', 'JAIME 2', 'TYRION 2', 'ARYA 2', 'CATELYN 2', 'JON 2', 'SANSA 2', 'ARYA 3', 'SAMWELL 1', 'TYRION 3', 'CATELYN 3', 'JAIME 3', 'ARYA 4', 'DAENERYS 2', 'BRAN 2', 'DAVOS 3', 'JON 3', 'DAENERYS 3', 'SANSA 3', 'ARYA 5', 'JON 4', 'JAIME 4', 'TYRION 4', 'SAMWELL 2', 'ARYA 6', 'CATELYN 4', 'DAVOS 4', 'JAIME 5', 'TYRION 5', 'ARYA 7', 'BRAN 3', 'JON 5', 'DAENERYS 4', 'ARYA 8', 'JAIME 6', 'CATELYN 5', 'SAMWELL 3', 'ARYA 9', 'JON 6', 'CATELYN 6', 'ARYA 10', 'CATELYN 7', 'ARYA 11', 'TYRION 6', 'DAVOS 5', 'JON 7', 'BRAN 4', 'DAENERYS 5', 'TYRION 7', 'SANSA 4', 'TYRION 8', 'SANSA 5', 'JAIME 7', 'DAVOS 6', 'JON 8', 'ARYA 12', 'TYRION 9', 'JAIME 8', 'SANSA 6', 'JON 9', 'TYRION 10', 'DAENERYS 6', 'JAIME 9', 'JON 10', 'ARYA 13', 'SAMWELL 4', 'JON 11', 'TYRION 11', 'SAMWELL 5', 'JON 12', 'SANSA 7', 'EPILOGUE 1'], ['PROLOGUE 1', 'THE PROPHET 1', 'THE CAPTAIN OF GUARDS 1', 'CERSEI 1', 'BRIENNE 1', 'SAMWELL 1', 'ARYA 1', 'CERSEI 2', 'JAIME 1', 'BRIENNE 2', 'SANSA 1', 'THE KRAKEN’S DAUGHTER 1', 'CERSEI 3', 'THE SOILED KNIGHT 1', 'BRIENNE 3', 'SAMWELL 2', 'JAIME 2', 'CERSEI 4', 'THE IRON CAPTAIN 1', 'THE DROWNED MAN 1', 'BRIENNE 4', 'THE QUEENMAKER 1', 'ARYA 2', 'ALAYNE 1', 'CERSEI 5', 'BRIENNE 5', 'SAMWELL 3', 'JAIME 3', 'CERSEI 6', 'THE REAVER 1', 'JAIME 4', 'BRIENNE 6', 'CERSEI 7', 'JAIME 5', 'CAT OF THE CANALS 1', 'SAMWELL 4', 'CERSEI 8', 'BRIENNE 7', 'JAIME 6', 'CERSEI 9', 'THE PRINCESS IN THE TOWER 1', 'ALAYNE 2', 'BRIENNE 8', 'CERSEI 10', 'JAIME 7', 'SAMWELL 5'], ['PROLOGUE 1', 'TYRION 1', 'DAENERYS 1', 'JON 1', 'BRAN 1', 'TYRION 2', 'THE MERCHANT’S MAN 1', 'JON 2', 'TYRION 3', 'DAVOS 1', 'JON 3', 'DAENERYS 2', 'REEK 1', 'BRAN 2', 'TYRION 4', 'DAVOS 2', 'DAENERYS 3', 'JON 4', 'TYRION 5', 'DAVOS 3', 'REEK 2', 'JON 5', 'TYRION 6', 'DAENERYS 4', 'THE LOST LORD 1', 'THE WINDBLOWN 1', 'THE WAYWARD BRIDE 1', 'TYRION 7', 'JON 6', 'DAVOS 4', 'DAENERYS 5', 'MELISANDRE 1', 'REEK 3', 'TYRION 8', 'BRAN 3', 'JON 7', 'DAENERYS 6', 'THE PRINCE OF WINTERFELL 1', 'THE WATCHER 1', 'JON 8', 'TYRION 9', 'THE TURNCLOAK 1', 'THE KING’S PRIZE 1', 'DAENERYS 7', 'JON 9', 'THE BLIND GIRL 1', 'A GHOST IN WINTERFELL 1', 'TYRION 10', 'JAIME 1', 'JON 10', 'DAENERYS 8', 'THEON 1', 'DAENERYS 9', 'JON 11', 'CERSEI 1', 'THE QUEENSGUARD 1', 'THE IRON SUITOR 1', 'TYRION 11', 'JON 12', 'THE DISCARDED KNIGHT 1', 'THE SPURNED SUITOR 1', 'THE GRIFFIN REBORN 1', 'THE SACRIFICE 1', 'VICTARION 1', 'THE UGLY LITTLE GIRL 1', 'CERSEI 2', 'TYRION 12', 'THE KINGBREAKER 1', 'THE DRAGONTAMER 1', 'JON 13', 'THE QUEEN’S HAND 1', 'DAENERYS 10', 'EPILOGUE 1']]\n"
     ]
    }
   ],
   "source": [
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31085e7-4baa-47bc-98cd-16c24e328f88",
   "metadata": {},
   "source": [
    "Need to manually mess with the AFFC and ADWD chapters - gonna be a bit of a pain\n",
    "\n",
    "Session died. Tears. Not gonna reload everything right now.\n",
    "\n",
    "#### Create Vocabulary from TOKENS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f041e64-3bb6-45ee-a1bd-0b572d3fecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = TOKENS # forgot it was supposed to be called CORPUS\n",
    "CORPUS = CORPUS[CORPUS.term_str != ''].copy() # get rid of random punctuation\n",
    "CORPUS['pos_group'] = CORPUS.pos.str[:2] # also didn't realize this was needed too\n",
    "\n",
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n')\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['p'] = VOCAB['n'] / VOCAB['n'].sum()\n",
    "VOCAB['s'] = 1 / VOCAB['p']\n",
    "VOCAB['i'] = np.log2(VOCAB['s']) \n",
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba18577c-3c91-495f-9e2d-379ecb8ab3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add features\n",
    "LIB['date'] = [1996, 1998, 2000, 2005, 2011]\n",
    "LIB['chap_labels'] = contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d61ed0-fca6-4735-914a-b31d5ba1e1b3",
   "metadata": {},
   "source": [
    "I understand that I'm short some metadata (I contemplated branching out into other book series, or a different type of ASOIAF books). But I like what I have going on here and am disinclined to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cee4e76e-1c9a-42f7-8ffa-85410bc887d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these two as they likely won't be changed again\n",
    "\n",
    "LIB.to_csv('output/LIB.csv', sep='|')\n",
    "CORPUS.to_csv('output/CORPUS.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b8818-2d15-4177-8dee-ec75f84995e5",
   "metadata": {},
   "source": [
    "#### Getting into BOW, TFIDF, and DFIDF\n",
    "\n",
    "No point keeping these separate. Need DFIDF in the VOCAB table, so may as well do it here.\n",
    "\n",
    "Chapter is the unit of observation most interesting to me, so that's what we're gonna go with here. TF method is 'sum' and IDF method is 'standard'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14c48d3-ba9c-4631-baa2-58bbf9af7886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag = ['book_id', 'chap_num']\n",
    "BOW = CORPUS.groupby(bag+['term_str']).term_str.count().to_frame('n')\n",
    "DTCM = BOW.n.unstack(fill_value=0)\n",
    "N = DTCM.shape[0]\n",
    "TF = (DTCM.T / DTCM.T.sum()).T\n",
    "DF = DTCM.astype('bool').sum()\n",
    "IDF = np.log2(N / DF)\n",
    "TFIDF = TF * IDF\n",
    "\n",
    "VOCAB['df'] = DF\n",
    "VOCAB['dfidf'] = VOCAB.df * np.log2(len(TFIDF)/VOCAB.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00bb5f2b-8b81-428b-97a6-f878b498cabb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>df</th>\n",
       "      <th>dfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leaves</th>\n",
       "      <td>244</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>7233.221311</td>\n",
       "      <td>12.820423</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaving</th>\n",
       "      <td>167</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>10568.299401</td>\n",
       "      <td>13.367456</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maybe</th>\n",
       "      <td>291</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>6064.969072</td>\n",
       "      <td>12.566285</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stupid</th>\n",
       "      <td>253</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>6975.913043</td>\n",
       "      <td>12.768166</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peace</th>\n",
       "      <td>272</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>6488.625000</td>\n",
       "      <td>12.663697</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laughing</th>\n",
       "      <td>183</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>9644.295082</td>\n",
       "      <td>13.235460</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woke</th>\n",
       "      <td>199</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8868.874372</td>\n",
       "      <td>13.114535</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fist</th>\n",
       "      <td>231</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>7640.285714</td>\n",
       "      <td>12.899411</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doors</th>\n",
       "      <td>235</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>7510.238298</td>\n",
       "      <td>12.874643</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>126</td>\n",
       "      <td>181.512147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorry</th>\n",
       "      <td>189</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>9338.126984</td>\n",
       "      <td>13.188917</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wouldn</th>\n",
       "      <td>192</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>9192.218750</td>\n",
       "      <td>13.166197</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meet</th>\n",
       "      <td>180</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>9805.033333</td>\n",
       "      <td>13.259307</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>among</th>\n",
       "      <td>194</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>9097.453608</td>\n",
       "      <td>13.151247</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ate</th>\n",
       "      <td>169</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>10443.230769</td>\n",
       "      <td>13.350280</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stared</th>\n",
       "      <td>165</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>10696.400000</td>\n",
       "      <td>13.384838</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swung</th>\n",
       "      <td>160</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>11030.662500</td>\n",
       "      <td>13.429232</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helm</th>\n",
       "      <td>293</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>6023.569966</td>\n",
       "      <td>12.556403</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>207</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>8526.115942</td>\n",
       "      <td>13.057673</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>177</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>9971.220339</td>\n",
       "      <td>13.283554</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weak</th>\n",
       "      <td>189</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>9338.126984</td>\n",
       "      <td>13.188917</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>125</td>\n",
       "      <td>181.508529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            n         p             s          i max_pos max_pos_group   df  \\\n",
       "term_str                                                                      \n",
       "leaves    244  0.000138   7233.221311  12.820423     NNS            NN  126   \n",
       "leaving   167  0.000095  10568.299401  13.367456     VBG            VB  126   \n",
       "maybe     291  0.000165   6064.969072  12.566285      RB            RB  126   \n",
       "stupid    253  0.000143   6975.913043  12.768166      JJ            JJ  126   \n",
       "peace     272  0.000154   6488.625000  12.663697      NN            NN  126   \n",
       "laughing  183  0.000104   9644.295082  13.235460     VBG            VB  126   \n",
       "woke      199  0.000113   8868.874372  13.114535     VBD            VB  126   \n",
       "fist      231  0.000131   7640.285714  12.899411      NN            NN  126   \n",
       "doors     235  0.000133   7510.238298  12.874643     NNS            NN  126   \n",
       "sorry     189  0.000107   9338.126984  13.188917      JJ            JJ  125   \n",
       "wouldn    192  0.000109   9192.218750  13.166197     VBP            VB  125   \n",
       "meet      180  0.000102   9805.033333  13.259307      VB            VB  125   \n",
       "among     194  0.000110   9097.453608  13.151247      IN            IN  125   \n",
       "ate       169  0.000096  10443.230769  13.350280     VBP            VB  125   \n",
       "stared    165  0.000093  10696.400000  13.384838     VBD            VB  125   \n",
       "swung     160  0.000091  11030.662500  13.429232     VBD            VB  125   \n",
       "helm      293  0.000166   6023.569966  12.556403      NN            NN  125   \n",
       "play      207  0.000117   8526.115942  13.057673      VB            VB  125   \n",
       "recall    177  0.000100   9971.220339  13.283554      VB            VB  125   \n",
       "weak      189  0.000107   9338.126984  13.188917      JJ            JJ  125   \n",
       "\n",
       "               dfidf  \n",
       "term_str              \n",
       "leaves    181.512147  \n",
       "leaving   181.512147  \n",
       "maybe     181.512147  \n",
       "stupid    181.512147  \n",
       "peace     181.512147  \n",
       "laughing  181.512147  \n",
       "woke      181.512147  \n",
       "fist      181.512147  \n",
       "doors     181.512147  \n",
       "sorry     181.508529  \n",
       "wouldn    181.508529  \n",
       "meet      181.508529  \n",
       "among     181.508529  \n",
       "ate       181.508529  \n",
       "stared    181.508529  \n",
       "swung     181.508529  \n",
       "helm      181.508529  \n",
       "play      181.508529  \n",
       "recall    181.508529  \n",
       "weak      181.508529  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sort_values(by='dfidf', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c3f3966-c631-43b3-8b26-db2ba9a6f6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now for stemming and stopwords\n",
    "\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "\n",
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58864bcd-8342-461a-9d22-ab0d57c4cd39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>df</th>\n",
       "      <th>dfidf</th>\n",
       "      <th>stop</th>\n",
       "      <th>porter_stem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>101702</td>\n",
       "      <td>0.057625</td>\n",
       "      <td>17.353700</td>\n",
       "      <td>4.117171</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>51224</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>34.454670</td>\n",
       "      <td>5.106628</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>39497</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>44.684558</td>\n",
       "      <td>5.481704</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>39269</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>44.944002</td>\n",
       "      <td>5.490057</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>35195</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>50.146498</td>\n",
       "      <td>5.648077</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               n         p          s         i max_pos max_pos_group   df  \\\n",
       "term_str                                                                     \n",
       "the       101702  0.057625  17.353700  4.117171      DT            DT  342   \n",
       "and        51224  0.029024  34.454670  5.106628      CC            CC  342   \n",
       "to         39497  0.022379  44.684558  5.481704      TO            TO  342   \n",
       "a          39269  0.022250  44.944002  5.490057      DT            DT  342   \n",
       "of         35195  0.019942  50.146498  5.648077      IN            IN  342   \n",
       "\n",
       "          dfidf  stop porter_stem  \n",
       "term_str                           \n",
       "the         0.0     1         the  \n",
       "and         0.0     1         and  \n",
       "to          0.0     1          to  \n",
       "a           0.0     1           a  \n",
       "of          0.0     1          of  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['porter_stem'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)\n",
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00e99ab9-21bb-49c0-99f6-571be4f52553",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv('output/VOCAB.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f98983b5-c181-47c3-9b2e-bd0b65ed7aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th>a</th>\n",
       "      <td>111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>above</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accustomed</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquiescence</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>across</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjusted</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admitted</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aemon</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 n     tfidf\n",
       "book_id chap_num term_str                   \n",
       "1       1        a             111  0.000000\n",
       "                 abandoned       2  0.001167\n",
       "                 about           4  0.000058\n",
       "                 above           1  0.000120\n",
       "                 accustomed      1  0.000876\n",
       "                 acquiescence    1  0.002186\n",
       "                 across          1  0.000026\n",
       "                 adjusted        1  0.001407\n",
       "                 admitted        1  0.000464\n",
       "                 aemon           2  0.001256"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the BOW, DCTM, and TFIDF matrices\n",
    "\n",
    "BOW['tfidf'] = TFIDF.stack()\n",
    "\n",
    "BOW.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40364ce1-ac8e-4806-8df1-688e372003b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>10th</th>\n",
       "      <th>15th</th>\n",
       "      <th>16th</th>\n",
       "      <th>23rd</th>\n",
       "      <th>57th</th>\n",
       "      <th>61st</th>\n",
       "      <th>a</th>\n",
       "      <th>aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee</th>\n",
       "      <th>aaaaaaoooooooooooooooooooooooo</th>\n",
       "      <th>aaaaahoooooooooooooooooooo</th>\n",
       "      <th>...</th>\n",
       "      <th>zekko</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zhak</th>\n",
       "      <th>zharaq</th>\n",
       "      <th>zigged</th>\n",
       "      <th>zo</th>\n",
       "      <th>zollo</th>\n",
       "      <th>zorse</th>\n",
       "      <th>zorses</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str          10th  15th  16th  23rd  57th  61st    a  \\\n",
       "book_id chap_num                                            \n",
       "1       1            0     0     0     0     0     0  111   \n",
       "        2            0     0     0     0     0     0   63   \n",
       "        3            0     0     0     0     0     0   41   \n",
       "        4            0     0     0     0     0     0   78   \n",
       "        5            0     0     0     0     0     0   86   \n",
       "\n",
       "term_str          aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee  \\\n",
       "book_id chap_num                                                          \n",
       "1       1                                                         0       \n",
       "        2                                                         0       \n",
       "        3                                                         0       \n",
       "        4                                                         0       \n",
       "        5                                                         0       \n",
       "\n",
       "term_str          aaaaaaoooooooooooooooooooooooo  aaaaahoooooooooooooooooooo  \\\n",
       "book_id chap_num                                                               \n",
       "1       1                                      0                           0   \n",
       "        2                                      0                           0   \n",
       "        3                                      0                           0   \n",
       "        4                                      0                           0   \n",
       "        5                                      0                           0   \n",
       "\n",
       "term_str          ...  zekko  zenith  zhak  zharaq  zigged  zo  zollo  zorse  \\\n",
       "book_id chap_num  ...                                                          \n",
       "1       1         ...      0       0     0       0       0   0      0      0   \n",
       "        2         ...      0       0     0       0       0   0      0      0   \n",
       "        3         ...      0       0     0       0       0   0      0      0   \n",
       "        4         ...      0       0     0       0       0   0      0      0   \n",
       "        5         ...      0       0     0       0       0   0      0      0   \n",
       "\n",
       "term_str          zorses  zzzs  \n",
       "book_id chap_num                \n",
       "1       1              0     0  \n",
       "        2              0     0  \n",
       "        3              0     0  \n",
       "        4              0     0  \n",
       "        5              0     0  \n",
       "\n",
       "[5 rows x 24235 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTCM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6d849-29f0-43b7-a1cb-2680de06e2ca",
   "metadata": {},
   "source": [
    "It may look like there's an issue with the source material, but there are actually just several different horn sounds in one particular chapter in *A Feast for Crows*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebaabbda-5f8f-4cc0-9c0b-54692189e64a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>10th</th>\n",
       "      <th>15th</th>\n",
       "      <th>16th</th>\n",
       "      <th>23rd</th>\n",
       "      <th>57th</th>\n",
       "      <th>61st</th>\n",
       "      <th>a</th>\n",
       "      <th>aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee</th>\n",
       "      <th>aaaaaaoooooooooooooooooooooooo</th>\n",
       "      <th>aaaaahoooooooooooooooooooo</th>\n",
       "      <th>...</th>\n",
       "      <th>zekko</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zhak</th>\n",
       "      <th>zharaq</th>\n",
       "      <th>zigged</th>\n",
       "      <th>zo</th>\n",
       "      <th>zollo</th>\n",
       "      <th>zorse</th>\n",
       "      <th>zorses</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str          10th  15th  16th  23rd  57th  61st    a  \\\n",
       "book_id chap_num                                            \n",
       "1       1          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        2          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        3          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        4          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "        5          0.0   0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "term_str          aaaaaaarrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee  \\\n",
       "book_id chap_num                                                          \n",
       "1       1                                                       0.0       \n",
       "        2                                                       0.0       \n",
       "        3                                                       0.0       \n",
       "        4                                                       0.0       \n",
       "        5                                                       0.0       \n",
       "\n",
       "term_str          aaaaaaoooooooooooooooooooooooo  aaaaahoooooooooooooooooooo  \\\n",
       "book_id chap_num                                                               \n",
       "1       1                                    0.0                         0.0   \n",
       "        2                                    0.0                         0.0   \n",
       "        3                                    0.0                         0.0   \n",
       "        4                                    0.0                         0.0   \n",
       "        5                                    0.0                         0.0   \n",
       "\n",
       "term_str          ...  zekko  zenith  zhak  zharaq  zigged   zo  zollo  zorse  \\\n",
       "book_id chap_num  ...                                                           \n",
       "1       1         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        2         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        3         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        4         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "        5         ...    0.0     0.0   0.0     0.0     0.0  0.0    0.0    0.0   \n",
       "\n",
       "term_str          zorses  zzzs  \n",
       "book_id chap_num                \n",
       "1       1            0.0   0.0  \n",
       "        2            0.0   0.0  \n",
       "        3            0.0   0.0  \n",
       "        4            0.0   0.0  \n",
       "        5            0.0   0.0  \n",
       "\n",
       "[5 rows x 24235 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f1462-dc20-4094-aa70-2b0b7616c65d",
   "metadata": {},
   "source": [
    "So I am guessing that \"reduced and normalized TFIDF_L2\" means I have to reduce it to some specific feature size, probably by DFIDF.\n",
    "\n",
    "I think I want to take out proper nouns (names) but probably keep verbs and adjectives? Is 5000 too many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c571313-b0b9-47f2-9b56-345fdbb4ade3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VSHORT = VOCAB[VOCAB.max_pos_group.isin(['NN', 'VB', 'JJ']) & ~VOCAB.max_pos.isin(['NNP'])].sort_values('dfidf', ascending=False).head(5000)\n",
    "\n",
    "TFIDF_5000 = TFIDF[VSHORT.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c5db9ef-bfeb-444d-9f72-51cac64ec01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74d3bf28-5666-4e6d-8caa-9c0466773372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TFIDF_L2\n",
    "\n",
    "TFIDF_L2 = (TFIDF_5000.T / norm(TFIDF_5000, 2, axis=1)).T\n",
    "\n",
    "a = len(TFIDF_L2)\n",
    "TFIDF_L2 = TFIDF_L2.dropna()\n",
    "b = len(TFIDF_L2)\n",
    "bag_loss = a - b\n",
    "bag_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9255b5c0-f899-41d5-9511-9b34fb024982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>woke</th>\n",
       "      <th>peace</th>\n",
       "      <th>leaves</th>\n",
       "      <th>stupid</th>\n",
       "      <th>laughing</th>\n",
       "      <th>doors</th>\n",
       "      <th>fist</th>\n",
       "      <th>leaving</th>\n",
       "      <th>recall</th>\n",
       "      <th>ate</th>\n",
       "      <th>...</th>\n",
       "      <th>cogs</th>\n",
       "      <th>washerwomen</th>\n",
       "      <th>shortsword</th>\n",
       "      <th>droll</th>\n",
       "      <th>reigned</th>\n",
       "      <th>wanton</th>\n",
       "      <th>dragonbone</th>\n",
       "      <th>flanks</th>\n",
       "      <th>fords</th>\n",
       "      <th>lair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>0.019153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>66</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str              woke     peace    leaves    stupid  laughing     doors  \\\n",
       "book_id chap_num                                                               \n",
       "1       1         0.000000  0.000000  0.043317  0.000000  0.000000  0.000000   \n",
       "        2         0.000000  0.000000  0.000000  0.000000  0.033562  0.000000   \n",
       "        3         0.000000  0.000000  0.025442  0.000000  0.000000  0.000000   \n",
       "        4         0.015683  0.000000  0.031367  0.000000  0.000000  0.031367   \n",
       "        5         0.000000  0.019001  0.000000  0.000000  0.000000  0.000000   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "5       66        0.000000  0.020986  0.000000  0.010493  0.000000  0.031479   \n",
       "        67        0.000000  0.000000  0.000000  0.000000  0.000000  0.100146   \n",
       "        68        0.000000  0.044976  0.000000  0.000000  0.014992  0.022488   \n",
       "        69        0.034008  0.008502  0.008502  0.008502  0.008502  0.000000   \n",
       "        70        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "term_str              fist   leaving    recall       ate  ...  cogs  \\\n",
       "book_id chap_num                                          ...         \n",
       "1       1         0.000000  0.000000  0.000000  0.000000  ...   0.0   \n",
       "        2         0.000000  0.000000  0.016915  0.000000  ...   0.0   \n",
       "        3         0.000000  0.000000  0.000000  0.000000  ...   0.0   \n",
       "        4         0.000000  0.000000  0.000000  0.000000  ...   0.0   \n",
       "        5         0.000000  0.019001  0.019153  0.000000  ...   0.0   \n",
       "...                    ...       ...       ...       ...  ...   ...   \n",
       "5       66        0.000000  0.000000  0.010577  0.000000  ...   0.0   \n",
       "        67        0.000000  0.000000  0.000000  0.010095  ...   0.0   \n",
       "        68        0.029984  0.000000  0.007556  0.000000  ...   0.0   \n",
       "        69        0.017004  0.000000  0.017140  0.025710  ...   0.0   \n",
       "        70        0.011513  0.000000  0.011605  0.000000  ...   0.0   \n",
       "\n",
       "term_str          washerwomen  shortsword  droll  reigned  wanton  dragonbone  \\\n",
       "book_id chap_num                                                                \n",
       "1       1                 0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "        2                 0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "        3                 0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "        4                 0.0    0.000000    0.0      0.0     0.0    0.102715   \n",
       "        5                 0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "...                       ...         ...    ...      ...     ...         ...   \n",
       "5       66                0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "        67                0.0    0.032795    0.0      0.0     0.0    0.000000   \n",
       "        68                0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "        69                0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "        70                0.0    0.000000    0.0      0.0     0.0    0.000000   \n",
       "\n",
       "term_str            flanks  fords      lair  \n",
       "book_id chap_num                             \n",
       "1       1         0.000000    0.0  0.000000  \n",
       "        2         0.000000    0.0  0.000000  \n",
       "        3         0.000000    0.0  0.000000  \n",
       "        4         0.000000    0.0  0.000000  \n",
       "        5         0.000000    0.0  0.000000  \n",
       "...                    ...    ...       ...  \n",
       "5       66        0.000000    0.0  0.000000  \n",
       "        67        0.000000    0.0  0.000000  \n",
       "        68        0.049094    0.0  0.049094  \n",
       "        69        0.000000    0.0  0.055683  \n",
       "        70        0.000000    0.0  0.000000  \n",
       "\n",
       "[342 rows x 5000 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7f7b63e-45a3-47ba-9a69-61727d67fb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOW.to_csv('output/BOW.csv', sep='|')\n",
    "DTCM.to_csv('output/DTM.csv', sep='|')\n",
    "TFIDF.to_csv('output/TFIDF.csv', sep='|')\n",
    "TFIDF_L2.to_csv('output/TFIDF_L2.csv', sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
